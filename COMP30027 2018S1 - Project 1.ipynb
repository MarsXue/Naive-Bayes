{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): Wenqing Xue\n",
    "###### Python version: 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the seven functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(filename):\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "    data = []\n",
    "    \n",
    "    for line in file.readlines():\n",
    "        data.append(line.strip().split(','))\n",
    "        \n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "def train_supervised(data):\n",
    "\n",
    "    # Prior probability\n",
    "    prior_dict = {}\n",
    "    # Posterior probability\n",
    "    poste_dict = {}\n",
    "    \n",
    "    # Calculate prior probability\n",
    "    for line in data:\n",
    "        res = line[-1]\n",
    "        if res not in prior_dict:\n",
    "            prior_dict[res] = 1\n",
    "        else:\n",
    "            prior_dict[res] += 1\n",
    "            \n",
    "    for k, v in prior_dict.items():\n",
    "        prior_dict[k] = v / len(data)\n",
    "    \n",
    "    # Calculate posterior probability\n",
    "    for att in range(len(data[0])-1):\n",
    "        res_dict = {}\n",
    "        for line in data:\n",
    "            res = line[-1]\n",
    "            if res not in res_dict:\n",
    "                res_dict[res] = {}\n",
    "            if line[att] in res_dict[line[-1]]:\n",
    "                res_dict[res][line[att]] += 1\n",
    "            else:\n",
    "                res_dict[res][line[att]] = 1\n",
    "        poste_dict[att] = res_dict\n",
    "\n",
    "    return prior_dict, poste_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised(data, prior_dict, poste_dict):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    sum_value = len(data)\n",
    "    for line in data:\n",
    "        class_dict = {}\n",
    "        for k, v in prior_dict.items():\n",
    "            class_dict[k] = v\n",
    "            for i in range(len(line)-1):\n",
    "                att = line[i]\n",
    "                if att != '?':\n",
    "                    sum_dict = sum(poste_dict[i][k].values())\n",
    "                    if att in poste_dict[i][k]:\n",
    "#                         class_dict[k] *= poste_dict[i][k][line[i]] / sum(poste_dict[i][k].values())\n",
    "                        class_dict[k] *= poste_dict[i][k][line[i]] / sum_dict\n",
    "                    else:\n",
    "                        # Epsilon smoothing\n",
    "#                         class_dict[k] *= 0.1 / sum(poste_dict[i][k].values())\n",
    "                        class_dict[k] *= 0.005 / sum_value\n",
    "        result.append(max(class_dict, key=class_dict.get))\n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(data, result):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == result[i]:\n",
    "            count += 1\n",
    "    \n",
    "    accuracy = count / len(data)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924913835548991\n"
     ]
    }
   ],
   "source": [
    "def supervised():\n",
    "    \n",
    "    data = preprocess('mushroom.csv')\n",
    "    prior_dict, poste_dict = train_supervised(data)\n",
    "    result = predict_supervised(data, prior_dict, poste_dict)\n",
    "    evaluate_supervised(data, result)\n",
    "    \n",
    "supervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised(data):\n",
    "    \n",
    "    # Calculate random values\n",
    "    class_dict = {} \n",
    "    for line in data:\n",
    "        class_dict[line[-1]] = 0\n",
    "    \n",
    "    ins_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        random_dict = class_dict.copy()\n",
    "        sum_random = 0\n",
    "        for k in random_dict.keys():\n",
    "            random_value = random.random()\n",
    "            random_dict[k] = random_value\n",
    "            sum_random += random_value\n",
    "            \n",
    "        for k in class_dict.keys():\n",
    "            random_dict[k] = random_dict[k] / sum_random\n",
    "\n",
    "        ins_dict[i] = random_dict\n",
    "    \n",
    "    # Prior probability\n",
    "    prior_dict = class_dict.copy()\n",
    "    # Posterior probability\n",
    "    poste_dict = {}\n",
    "    \n",
    "    # Calculate prior probability\n",
    "    for k, v in ins_dict.items():\n",
    "        for ks, vs in v.items():\n",
    "            prior_dict[ks] += vs\n",
    "    \n",
    "    for k, v in prior_dict.items():\n",
    "        prior_dict[k] = v / len(ins_dict)\n",
    "    \n",
    "    # Calculate posterior probability\n",
    "    for att in range(len(data[0])-1):\n",
    "        res_dict = {}\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            for k in class_dict.keys():\n",
    "                if k not in res_dict:\n",
    "                    res_dict[k] = {}\n",
    "\n",
    "                if data[i][att] not in res_dict[k]:\n",
    "                    res_dict[k][data[i][att]] = ins_dict[i][k]\n",
    "                else:\n",
    "                    res_dict[k][data[i][att]] += ins_dict[i][k]\n",
    "                    \n",
    "        poste_dict[att] = res_dict\n",
    "\n",
    "    for att in range(len(data[0])-1):\n",
    "        for k in class_dict.keys():\n",
    "            sum_value = sum(poste_dict[att][k].values())\n",
    "            for ks, vs in poste_dict[att][k].items():\n",
    "                poste_dict[att][k][ks] = vs / sum_value\n",
    "    \n",
    "    total_dict = {}\n",
    "    for ins in range(len(data)):\n",
    "        value_dict = {}\n",
    "        \n",
    "        for cla in class_dict.keys():\n",
    "            value_dict[cla] = prior_dict[cla]\n",
    "            for att in range(len(data[ins])-1):\n",
    "                value_dict[cla] *= poste_dict[att][cla][data[ins][att]]\n",
    "        sum_value = sum(value_dict.values())\n",
    "        for k, v in value_dict.items():\n",
    "            value_dict[k] = v / sum_value\n",
    "        total_dict[ins] = value_dict\n",
    "\n",
    "    return prior_dict, total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised(data, prior_dict, total_dict):\n",
    "    \n",
    "    poste_dict = {}\n",
    "    \n",
    "    # Calculate prior probability\n",
    "    for k, v in total_dict.items():\n",
    "        for ks, vs in v.items():\n",
    "            prior_dict[ks] += vs\n",
    "    \n",
    "    for k, v in prior_dict.items():\n",
    "        prior_dict[k] = v / len(total_dict)\n",
    "    \n",
    "    # Calculate posterior probability\n",
    "    for att in range(len(data[0])-1):\n",
    "        res_dict = {}\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            for k in prior_dict.keys():\n",
    "                if k not in res_dict:\n",
    "                    res_dict[k] = {}\n",
    "                if data[i][att] != '?':\n",
    "                    if data[i][att] not in res_dict[k]:\n",
    "                        res_dict[k][data[i][att]] = total_dict[i][k]\n",
    "                    else:\n",
    "                        res_dict[k][data[i][att]] += total_dict[i][k]\n",
    "                    \n",
    "        poste_dict[att] = res_dict\n",
    "\n",
    "    for att in range(len(data[0])-1):\n",
    "        for k in prior_dict.keys():\n",
    "            sum_value = sum(poste_dict[att][k].values())\n",
    "            for ks, vs in poste_dict[att][k].items():\n",
    "                poste_dict[att][k][ks] = vs / sum_value\n",
    "    \n",
    "    tmp_dict = {}\n",
    "    for ins in range(len(data)):\n",
    "        value_dict = {}\n",
    "        \n",
    "        for cla in prior_dict.keys():\n",
    "            value_dict[cla] = prior_dict[cla]\n",
    "            for att in range(len(data[ins])-1):\n",
    "                if data[ins][att] != '?':\n",
    "                    value_dict[cla] *= poste_dict[att][cla][data[ins][att]]\n",
    "        sum_value = sum(value_dict.values())\n",
    "        for k, v in value_dict.items():\n",
    "            value_dict[k] = v / sum_value\n",
    "        tmp_dict[ins] = value_dict\n",
    "    \n",
    "    return prior_dict, tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised(data, result):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == result[i]:\n",
    "            count += 1\n",
    "    \n",
    "    accuracy = count / len(data)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8924175283111767\n",
      "Accuracy: 0.8924175283111767\n",
      "Accuracy: 0.5999507631708518\n",
      "Accuracy: 0.8724766125061546\n",
      "Accuracy: 0.8916789758739537\n",
      "Accuracy: 0.5226489414081733\n",
      "Accuracy: 0.8417035942885278\n",
      "Accuracy: 0.8959871984244214\n",
      "Accuracy: 0.8645987198424422\n",
      "Accuracy: 0.8920482520925652\n",
      "Average: 0.8165928114229443\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def unsupervised():\n",
    "    \n",
    "    data = preprocess('mushroom.csv')\n",
    "    prior_dict, total_dict = train_unsupervised(data)\n",
    "    \n",
    "    for i in range(5):\n",
    "        prior_dict, total_dict = predict_unsupervised(data, prior_dict, total_dict)\n",
    "        \n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        result.append(max(total_dict[i], key=total_dict[i].get))\n",
    "    \n",
    "    prior_list = list(prior_dict)\n",
    "    classifier = []\n",
    "    for r in result:\n",
    "        for i in range(len(prior_list)):\n",
    "            if r == prior_list[i]:\n",
    "                classifier.append(i)\n",
    "    \n",
    "    class_num = len(set(result))\n",
    "    class_list = list(set(result))\n",
    "    class_list *= class_num\n",
    "\n",
    "    predict_class = set()\n",
    "    for i in list(permutations(class_list, class_num)):\n",
    "        predict_class.add(i)\n",
    "        \n",
    "    actual_list = [line[-1] for line in data]\n",
    "    \n",
    "    result_list = []\n",
    "    for clas in list(predict_class):\n",
    "        res = []\n",
    "        correct = 0\n",
    "        for i in classifier:\n",
    "            res.append(clas[i])\n",
    "        result_list.append(res)\n",
    "    \n",
    "    count_list = []\n",
    "    for res in result_list:\n",
    "        count = 0\n",
    "        for i in range(len(res)):\n",
    "            if res[i] == actual_list[i]:\n",
    "                count += 1\n",
    "        count_list.append(count/len(res))\n",
    "\n",
    "    index = count_list.index(max(count_list))\n",
    "    swapped_result = result_list[index]\n",
    "    \n",
    "    acc = evaluate_unsupervised(data, swapped_result)\n",
    "    return acc\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(10):\n",
    "    acc = unsupervised()\n",
    "    count += acc\n",
    "print(\"Average:\", count / 10)\n",
    "print('-'*80)\n",
    "\n",
    "# unsupervised()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1 Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
